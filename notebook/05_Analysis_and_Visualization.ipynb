{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 5: Analysis & Visualization\n",
                "\n",
                "**Data-Juicer User Guide**\n",
                "\n",
                "- Git Commit: `v1.0.5`\n",
                "- Commit Date: 2026-01-16\n",
                "- Repository: https://github.com/datajuicer/data-juicer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Table of Contents\n",
                "\n",
                "1. [Setup](#setup)\n",
                "2. [Create Sample Dataset](#create-sample-dataset)\n",
                "3. [Run Data Analysis](#run-data-analysis)\n",
                "4. [Interpret Analysis Results](#interpret-analysis-results)\n",
                "5. [Compare Before and After Processing](#compare-before-and-after-processing)\n",
                "6. [Further Reading](#further-reading)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Sample Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs('./data', exist_ok=True)\n",
                "\n",
                "# Create diverse dataset for analysis\n",
                "samples = [\n",
                "    {\"text\": \"Short text.\"},\n",
                "    {\"text\": \"This is a medium-length text sample for analysis.\"},\n",
                "    {\"text\": \"This is a longer text sample that contains more words and provides better content for statistical analysis of text length distribution.\"},\n",
                "    {\"text\": \"Another medium sample.\"},\n",
                "    {\"text\": \"Very short.\"},\n",
                "    {\"text\": \"Machine learning and artificial intelligence are transforming how we process and analyze large-scale datasets.\"},\n",
                "    {\"text\": \"Data quality is crucial.\"},\n",
                "    {\"text\": \"This text has a good balance of length and content quality for demonstration purposes.\"},\n",
                "    {\"text\": \"x\"},\n",
                "    {\"text\": \"The quick brown fox jumps over the lazy dog.\"}\n",
                "]\n",
                "\n",
                "with open('./data/analysis_demo.jsonl', 'w') as f:\n",
                "    for sample in samples:\n",
                "        f.write(json.dumps(sample) + '\\n')\n",
                "\n",
                "print(f\"Created dataset with {len(samples)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create analysis configuration\n",
                "analysis_config = \"\"\"project_name: 'analysis_demo'\n",
                "dataset_path: './data/analysis_demo.jsonl'\n",
                "export_path: './outputs/analysis_demo/analyzed.jsonl'\n",
                "np: 2\n",
                "\n",
                "export_original_dataset: true # Keep original dataset for further processing\n",
                "\n",
                "# Operators to compute statistics\n",
                "process:\n",
                "  - language_id_score_filter:\n",
                "      lang: 'en'\n",
                "      min_score: 0.5\n",
                "  - text_length_filter:\n",
                "      min_len: 5\n",
                "      max_len: 500\n",
                "  - alphanumeric_filter:\n",
                "      min_ratio: 0.3\n",
                "\"\"\"\n",
                "\n",
                "os.makedirs('./configs', exist_ok=True)\n",
                "with open('./configs/analysis.yaml', 'w') as f:\n",
                "    f.write(analysis_config)\n",
                "\n",
                "print(\"Analysis configuration created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run analysis\n",
                "!dj-analyze --config ./configs/analysis.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Interpret Analysis Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load overall statistics\n",
                "stats_file = './outputs/analysis_demo/analysis/overall.csv'\n",
                "if os.path.exists(stats_file):\n",
                "    overall_stats = pd.read_csv(stats_file)\n",
                "    print(\"Overall Statistics:\")\n",
                "    print(overall_stats)\n",
                "else:\n",
                "    print(\"Statistics file not found. Analysis may still be running.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display generated histograms\n",
                "analysis_dir = './outputs/analysis_demo/analysis'\n",
                "if os.path.exists(analysis_dir):\n",
                "    png_files = [f for f in os.listdir(analysis_dir) if f.endswith('.png')]\n",
                "    \n",
                "    if png_files:\n",
                "        print(f\"Found {len(png_files)} visualization(s)\\n\")\n",
                "        \n",
                "        for png_file in png_files[:3]:  # Show first 3\n",
                "            img_path = os.path.join(analysis_dir, png_file)\n",
                "            img = Image.open(img_path)\n",
                "            \n",
                "            plt.figure(figsize=(10, 6))\n",
                "            plt.imshow(img)\n",
                "            plt.axis('off')\n",
                "            plt.title(png_file)\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "    else:\n",
                "        print(\"No visualization files found\")\n",
                "else:\n",
                "    print(\"Analysis directory not found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compare Before and After Processing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!dj-process --config ./configs/analysis.yaml \\\n",
                "    --dataset_path ./outputs/analysis_demo/analyzed.jsonl \\\n",
                "    --export_path ./outputs/process_demo/processed.jsonl \\\n",
                "    --keep_stats_in_res_ds true"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!dj-analyze --config ./configs/analysis.yaml \\\n",
                "    --dataset_path ./outputs/process_demo/processed.jsonl \\\n",
                "    --export_path ./outputs/processed_analyzed/analyzed.jsonl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare Before and After Processing\n",
                "import matplotlib.gridspec as gridspec\n",
                "\n",
                "before_dir = './outputs/analysis_demo/analysis'\n",
                "after_dir = './outputs/processed_analyzed/analysis'\n",
                "\n",
                "# Get PNG files from both directories\n",
                "before_files = sorted([f for f in os.listdir(before_dir) if f.endswith('.png')]) if os.path.exists(before_dir) else []\n",
                "after_files = sorted([f for f in os.listdir(after_dir) if f.endswith('.png')]) if os.path.exists(after_dir) else []\n",
                "\n",
                "if before_files and after_files:\n",
                "    print(f\"Comparing {len(before_files)} visualizations before and after processing\\n\")\n",
                "    \n",
                "    # Compare matching files\n",
                "    for i, (before_file, after_file) in enumerate(zip(before_files[:2], after_files[:2])):\n",
                "        before_path = os.path.join(before_dir, before_file)\n",
                "        after_path = os.path.join(after_dir, after_file)\n",
                "        \n",
                "        before_img = Image.open(before_path)\n",
                "        after_img = Image.open(after_path)\n",
                "        \n",
                "        # Create side-by-side comparison\n",
                "        fig = plt.figure(figsize=(16, 6))\n",
                "        gs = gridspec.GridSpec(1, 2, figure=fig, wspace=0.3)\n",
                "        \n",
                "        # Before processing\n",
                "        ax1 = fig.add_subplot(gs[0, 0])\n",
                "        ax1.imshow(before_img)\n",
                "        ax1.set_title(f'Before Processing\\n{before_file}', fontsize=12, fontweight='bold')\n",
                "        ax1.axis('off')\n",
                "        \n",
                "        # After processing\n",
                "        ax2 = fig.add_subplot(gs[0, 1])\n",
                "        ax2.imshow(after_img)\n",
                "        ax2.set_title(f'After Processing\\n{after_file}', fontsize=12, fontweight='bold')\n",
                "        ax2.axis('off')\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "else:\n",
                "    print(\"Missing analysis directories or no visualization files found\")\n",
                "    if not before_files:\n",
                "        print(f\"  - Before: {before_dir} not found or empty\")\n",
                "    if not after_files:\n",
                "        print(f\"  - After: {after_dir} not found or empty\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Further Reading\n",
                "\n",
                "- [Analysis Tools](https://github.com/datajuicer/data-juicer/blob/main/tools/analyze_data.py)\n",
                "- [Operators Documentation](https://datajuicer.github.io/data-juicer/en/main/docs/Operators.html)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "data-juicer-nk",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
