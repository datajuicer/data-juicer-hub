{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 5: Operators Usage\n",
                "\n",
                "**Data-Juicer User Guide**\n",
                "\n",
                "- Git Commit: `v1.4.5`\n",
                "- Commit Date: 2026-01-16\n",
                "- Repository: https://github.com/datajuicer/data-juicer\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Operators are the core building blocks of Data-Juicer pipelines. This chapter demonstrates how to use operators programmatically through the Python API.\n",
                "\n",
                "There are two primary ways to use operators:\n",
                "\n",
                "1. **YAML Configuration** (declarative): Define your pipeline in a YAML file and execute it with the CLI\n",
                "2. **Python API** (programmatic): Instantiate and chain operators directly in Python code\n",
                "\n",
                "Both approaches offer flexibility—choose based on your workflow preferences.\n",
                "\n",
                "**Note:** For a complete list of operators and their parameters, refer to the [Operators Documentation](https://datajuicer.github.io/data-juicer/en/main/docs/Operators.html)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Table of Contents\n",
                "\n",
                "1. [YAML-Based Configuration](#yaml-based-configuration)\n",
                "2. [Operator Types](#operator-types)\n",
                "3. [Setup](#setup)\n",
                "4. [Create Sample Dataset](#create-sample-dataset)\n",
                "5. [Initialize and Call a Single Operator](#initialize-and-call-a-single-operator)\n",
                "6. [Chain Multiple Operators Sequentially](#chain-multiple-operators-sequentially)\n",
                "7. [Batch Processing with Operator List](#batch-processing-with-operator-list)\n",
                "8. [Inspect Operator Statistics](#inspect-operator-statistics)\n",
                "9.  [Further Reading](#further-reading)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## YAML-Based Configuration\n",
                "\n",
                "For declarative configuration, define your operator pipeline in a YAML file:\n",
                "\n",
                "```yaml\n",
                "project_name: 'operators_demo'\n",
                "dataset_path: './data/operators_demo.jsonl'\n",
                "export_path: './outputs/operators_demo.jsonl'\n",
                "np: 1\n",
                "\n",
                "process:\n",
                "  - whitespace_normalization_mapper: {}\n",
                "  - clean_email_mapper: {}\n",
                "  - language_id_score_filter:\n",
                "      lang: 'en'\n",
                "      min_score: 0.8\n",
                "  - text_length_filter:\n",
                "      min_len: 20\n",
                "      max_len: 200\n",
                "  - alphanumeric_filter:\n",
                "      min_ratio: 0.5\n",
                "```\n",
                "\n",
                "Execute the configuration file using the following command:\n",
                "\n",
                "```bash\n",
                "dj-process --config config.yaml\n",
                "```\n",
                "\n",
                "For detailed guidance on creating and using recipe YAML files, please refer to [Building Recipes](./02_Building_Recipes.ipynb)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Operator Types\n",
                "\n",
                "Data-Juicer provides several operator categories:\n",
                "\n",
                "| Operator Type | Purpose | Examples |\n",
                "|---|---|---|\n",
                "| **Mapper** | Edits and transforms samples. | `CleanEmailMapper`, `WhitespaceNormalizationMapper` |\n",
                "| **Filter** | Removes low-quality samples based on criteria | `LanguageIDScoreFilter`, `TextLengthFilter`, `AlphanumericFilter` |\n",
                "| **Deduplicator** | Detects and removes duplicate samples. | `DocumentDeduplicator`, `ImageDeduplicator` |\n",
                "| **Selector** | Selects top samples based on ranking. | `TopkSpecifiedFieldSelector` |\n",
                "| **Grouper** | Group samples to batched samples. | `KeyValueGrouper` |\n",
                "| **Aggregator** | \tAggregate for batched samples, such as summary or conclusion. | `MetaTagsAggregator` |\n",
                "| **Pipeline** | Applies dataset-level processing; both input and output are datasets. | `RayVLLMEnginePipeline` |\n",
                "\n",
                "Each operator can be configured with specific parameters to suit your data processing requirements."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Data-Juicer (if not installed)\n",
                "# !uv pip install py-data-juicer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from data_juicer.core.data import NestedDataset as Dataset\n",
                "from data_juicer.ops.filter import LanguageIDScoreFilter, TextLengthFilter, AlphanumericFilter\n",
                "from data_juicer.ops.mapper import CleanEmailMapper, WhitespaceNormalizationMapper"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Sample Dataset\n",
                "\n",
                "We'll create a sample dataset with varied data quality to demonstrate how different operators handle various scenarios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sample data with various quality levels\n",
                "samples = [\n",
                "    {\"text\": \"This is a high-quality English text sample.\"},\n",
                "    {\"text\": \"Short\"},\n",
                "    {\"text\": \"Contact us at support@example.com for more information.\"},\n",
                "    {\"text\": \"Bonjour! Ceci est un texte en français.\"},\n",
                "    {\"text\": \"Machine learning is transforming industries worldwide.\"},\n",
                "    {\"text\": \"a@#$%^&*()_+{}[]|\\\\:;<>?,./\"},\n",
                "    {\"text\": \"This has\\textra\twhitespace　issues.\"}\n",
                "]\n",
                "\n",
                "# Create Dataset object\n",
                "dataset = Dataset.from_list(samples)\n",
                "print(f\"Created dataset with {len(dataset)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize and Call a Single Operator\n",
                "\n",
                "Start by applying a single operator to understand how they work. Here we use `LanguageIDScoreFilter` to keep only English texts above a confidence threshold."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize LanguageIDScoreFilter\n",
                "lang_filter = LanguageIDScoreFilter(\n",
                "    lang='en',      # Keep English samples\n",
                "    min_score=0.6   # Minimum confidence score\n",
                ")\n",
                "\n",
                "# Apply the filter\n",
                "filtered_dataset = lang_filter.run(dataset)\n",
                "\n",
                "print(f\"Original: {len(dataset)} samples\")\n",
                "print(f\"After language filter: {len(filtered_dataset)} samples\")\n",
                "print(\"\\nFiltered samples:\")\n",
                "for i, sample in enumerate(filtered_dataset, 1):\n",
                "    print(f\"{i}. {sample['text']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain Multiple Operators Sequentially\n",
                "\n",
                "In practice, you'll often want to apply multiple operators in sequence. This approach gives you fine-grained control over the pipeline and allows you to inspect intermediate results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Method 1: Sequential application\n",
                "dataset = Dataset.from_list(samples)\n",
                "\n",
                "# Step 1: Normalize whitespace\n",
                "print(\"Step 1: Normalizing whitespace...\")\n",
                "whitespace_mapper = WhitespaceNormalizationMapper()\n",
                "dataset = whitespace_mapper.run(dataset)\n",
                "print(f\"  → {len(dataset)} samples\")\n",
                "\n",
                "# Step 2: Filter by language\n",
                "print(\"Step 2: Filtering by language (English, min_score=0.6)...\")\n",
                "lang_filter = LanguageIDScoreFilter(lang='en', min_score=0.6)\n",
                "dataset = lang_filter.run(dataset)\n",
                "print(f\"  → {len(dataset)} samples\")\n",
                "\n",
                "# Step 3: Filter by text length\n",
                "print(\"Step 3: Filtering by text length (20-200 chars)...\")\n",
                "length_filter = TextLengthFilter(min_len=20, max_len=200)\n",
                "dataset = length_filter.run(dataset)\n",
                "print(f\"  → {len(dataset)} samples\")\n",
                "\n",
                "# Step 4: Filter by alphanumeric ratio\n",
                "print(\"Step 4: Filtering by alphanumeric ratio (min=0.5)...\")\n",
                "alpha_filter = AlphanumericFilter(min_ratio=0.5)\n",
                "dataset = alpha_filter.run(dataset)\n",
                "print(f\"  → {len(dataset)} samples\")\n",
                "\n",
                "print(\"\\nFinal output:\")\n",
                "for i, sample in enumerate(dataset, 1):\n",
                "    print(f\"{i}. {sample['text']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Batch Processing with Operator List\n",
                "\n",
                "For cleaner code and better performance, you can pass all operators to the `process()` method at once."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Method 2: Using process() with operator list\n",
                "dataset = Dataset.from_list(samples)\n",
                "\n",
                "# Define operator pipeline\n",
                "operators = [\n",
                "    WhitespaceNormalizationMapper(),\n",
                "    CleanEmailMapper(),\n",
                "    LanguageIDScoreFilter(lang='en', min_score=0.8),\n",
                "    TextLengthFilter(min_len=20, max_len=200),\n",
                "    AlphanumericFilter(min_ratio=0.5)\n",
                "]\n",
                "\n",
                "# Apply all operators in one call\n",
                "dataset = dataset.process(operators)\n",
                "\n",
                "print(f\"Processed dataset: {len(dataset)} samples\")\n",
                "print(\"\\nFinal output:\")\n",
                "for i, sample in enumerate(dataset, 1):\n",
                "    print(f\"{i}. {sample['text']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Inspect Operator Statistics\n",
                "\n",
                "Filter operators can be configured to compute statistics without filtering. This helps you understand your dataset characteristics before deciding on filter thresholds."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create fresh dataset\n",
                "dataset = Dataset.from_list(samples)\n",
                "\n",
                "# Compute statistics without filtering\n",
                "length_filter = TextLengthFilter(min_len=20, max_len=200)\n",
                "dataset_with_stats = length_filter.run(dataset, reduce=False)  # Compute stats without filtering\n",
                "\n",
                "# Check statistics\n",
                "print(\"Text length statistics:\")\n",
                "for i, sample in enumerate(dataset_with_stats, 1):\n",
                "    stats = sample.get('__dj__stats__', {})\n",
                "    print(f\"{i}. Text: {sample['text'][:50]}...\")\n",
                "    print(f\"   Length: {stats.get('text_len', 'N/A')} chars\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Further Reading\n",
                "\n",
                "- [Complete Operators List](https://datajuicer.github.io/data-juicer/en/main/docs/Operators.html)\n",
                "- [Building Recipes with YAML](./02_Building_Recipes.ipynb)\n",
                "- [Developer Guide](https://datajuicer.github.io/data-juicer/en/main/docs/DeveloperGuide.html)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "data-juicer-nk",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
