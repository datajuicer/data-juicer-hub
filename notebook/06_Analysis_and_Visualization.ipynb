{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chapter 6: Analysis & Visualization\n",
                "\n",
                "**Data-Juicer User Guide**\n",
                "\n",
                "- Git Commit: `v1.4.5`\n",
                "- Commit Date: 2026-01-16\n",
                "- Repository: https://github.com/datajuicer/data-juicer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Table of Contents\n",
                "\n",
                "1. [Setup](#setup)\n",
                "2. [Create Sample Dataset](#create-sample-dataset)\n",
                "3. [Run Data Analysis](#run-data-analysis)\n",
                "4. [Show Analysis Results and Extract Parameters](#show-analysis-results-and-extract-parameters)\n",
                "5. [Create Optimized Config File](#create-optimized-config-file)\n",
                "6. [Process with Optimized Parameters](#process-with-optimized-parameters)\n",
                "7. [Further Reading](#further-reading)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Data-Juicer (if not installed)\n",
                "# !uv pip install py-data-juicer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Sample Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs('./data', exist_ok=True)\n",
                "\n",
                "# Create diverse dataset for analysis\n",
                "samples = [\n",
                "    # Low quality samples (should be filtered)\n",
                "    {\"text\": \"!!!Click here NOW!!! Buy cheap stuff!!! Limited time offer!!!\"},\n",
                "    {\"text\": \"Short text.\"},\n",
                "    {\"text\": \"x\"},\n",
                "    {\"text\": \"ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€ðŸ˜€\"},\n",
                "    \n",
                "    # Medium quality samples\n",
                "    {\"text\": \"This is OK but might need refinement for better quality and depth.\"},\n",
                "    {\"text\": \"The product is good. I like it. It works well. Very nice.\"},\n",
                "    {\"text\": \"Check this out: https://spam.com/fake https://scam.org/malware https://bad.link\"},\n",
                "    \n",
                "    # High quality samples (should be kept)\n",
                "    {\"text\": \"Machine learning has revolutionized natural language processing by enabling models to understand context, semantics, and generate human-like text through transformer architectures.\"},\n",
                "    {\"text\": \"Climate change poses significant challenges to global ecosystems. Rising temperatures affect biodiversity, ocean levels, and weather patterns, requiring coordinated international action.\"},\n",
                "    {\"text\": \"The Renaissance period marked a cultural rebirth in Europe, characterized by advances in art, science, and philosophy. Leonardo da Vinci and Michelangelo epitomized this era's creative genius.\"},\n",
                "    {\"text\": \"Quantum computing leverages quantum mechanical phenomena like superposition and entanglement to solve complex problems exponentially faster than classical computers in specific domains.\"},\n",
                "    {\"text\": \"Effective data curation involves filtering noise, removing duplicates, standardizing formats, and ensuring diversity to create high-quality training datasets for machine learning models.\"},\n",
                "    \n",
                "    # Edge cases\n",
                "    {\"text\": \"\"},\n",
                "    {\"text\": \"   \"},\n",
                "]\n",
                "\n",
                "\n",
                "with open('./data/analysis_demo.jsonl', 'w') as f:\n",
                "    for sample in samples:\n",
                "        f.write(json.dumps(sample) + '\\n')\n",
                "\n",
                "print(f\"Created dataset with {len(samples)} samples\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create analysis configuration\n",
                "analysis_config = \"\"\"project_name: 'analysis_demo'\n",
                "dataset_path: './data/analysis_demo.jsonl'\n",
                "export_path: './outputs/analysis_demo/analyzed.jsonl'\n",
                "np: 2\n",
                "\n",
                "export_original_dataset: true # Keep original dataset for further processing\n",
                "\n",
                "# Operators to compute statistics\n",
                "process:\n",
                "  - language_id_score_filter:\n",
                "      lang: 'en'\n",
                "      min_score: 0.5\n",
                "  - text_length_filter:\n",
                "      min_len: 5\n",
                "      max_len: 500\n",
                "  - alphanumeric_filter:\n",
                "      min_ratio: 0.3\n",
                "\"\"\"\n",
                "\n",
                "os.makedirs('./configs', exist_ok=True)\n",
                "with open('./configs/analysis.yaml', 'w') as f:\n",
                "    f.write(analysis_config)\n",
                "\n",
                "print(\"Analysis configuration created\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run analysis\n",
                "!dj-analyze --config ./configs/analysis.yaml"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Show Analysis Results and Extract Parameters\n",
                "\n",
                "After running the analysis, let's examine the statistical distributions and use them to determine optimal filtering thresholds."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Data Distributions\n",
                "\n",
                "The analysis results (including visualizations and statistics) are automatically saved in the `analysis` folder within the same directory as the `export_path`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Display generated histograms\n",
                "analysis_dir = './outputs/analysis_demo/analysis'\n",
                "if os.path.exists(analysis_dir):\n",
                "    png_files = [f for f in os.listdir(analysis_dir) if f.endswith('.png')]\n",
                "    \n",
                "    if png_files:\n",
                "        print(f\"Found {len(png_files)} visualization(s), here are the first 3:\\n\")\n",
                "        \n",
                "        for png_file in png_files[:3]:  # Show first 3\n",
                "            img_path = os.path.join(analysis_dir, png_file)\n",
                "            img = Image.open(img_path)\n",
                "            \n",
                "            plt.figure(figsize=(10, 6))\n",
                "            plt.imshow(img)\n",
                "            plt.axis('off')\n",
                "            plt.title(png_file)\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "    else:\n",
                "        print(\"No visualization files found\")\n",
                "else:\n",
                "    print(\"Analysis directory not found\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Extract Statistical Insights\n",
                "\n",
                "Now we'll load the overall statistics and use **percentile-based filtering** to determine optimal thresholds:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load overall statistics\n",
                "stats_file = './outputs/analysis_demo/analysis/overall.csv'\n",
                "if os.path.exists(stats_file):\n",
                "    overall_stats = pd.read_csv(stats_file)\n",
                "    print(\"Overall Statistics:\")\n",
                "    print(overall_stats)\n",
                "    \n",
                "    # Extract key statistics for parameter tuning\n",
                "    print(\"\\n=== Analysis-Based Parameter Recommendations ===\\n\")\n",
                "    \n",
                "    # 1. Language Score Analysis - use 25th percentile\n",
                "    lang_score_25th = overall_stats.loc[overall_stats['Unnamed: 0'] == '25%', 'lang_score'].values[0]\n",
                "    lang_score_mean = overall_stats.loc[overall_stats['Unnamed: 0'] == 'mean', 'lang_score'].values[0]\n",
                "    print(f\"1. Language Score Filter:\")\n",
                "    print(f\"   - Mean score: {lang_score_mean:.4f}\")\n",
                "    print(f\"   - 25th percentile: {lang_score_25th:.4f}\")\n",
                "    print(f\"   - Recommendation: Set min_score to {lang_score_25th:.4f} (filters bottom 25%)\")\n",
                "    \n",
                "    # 2. Text Length Analysis - use 25th percentile\n",
                "    text_len_25th = overall_stats.loc[overall_stats['Unnamed: 0'] == '25%', 'text_len'].values[0]\n",
                "    text_len_mean = overall_stats.loc[overall_stats['Unnamed: 0'] == 'mean', 'text_len'].values[0]\n",
                "    text_len_75th = overall_stats.loc[overall_stats['Unnamed: 0'] == '75%', 'text_len'].values[0]\n",
                "    text_len_max = overall_stats.loc[overall_stats['Unnamed: 0'] == 'max', 'text_len'].values[0]\n",
                "    print(f\"\\n2. Text Length Filter:\")\n",
                "    print(f\"   - Mean length: {text_len_mean:.1f}\")\n",
                "    print(f\"   - 25th percentile: {text_len_25th:.0f}\")\n",
                "    print(f\"   - 75th percentile: {text_len_75th:.0f}\")\n",
                "    print(f\"   - Recommendation: Set min_len={text_len_25th:.0f} (filters bottom 25%), max_len={text_len_75th * 1.5:.0f}\")\n",
                "    \n",
                "    # 3. Alphanumeric Ratio Analysis - use 25th percentile\n",
                "    alnum_25th = overall_stats.loc[overall_stats['Unnamed: 0'] == '25%', 'alnum_ratio'].values[0]\n",
                "    alnum_mean = overall_stats.loc[overall_stats['Unnamed: 0'] == 'mean', 'alnum_ratio'].values[0]\n",
                "    print(f\"\\n3. Alphanumeric Filter:\")\n",
                "    print(f\"   - Mean ratio: {alnum_mean:.4f}\")\n",
                "    print(f\"   - 25th percentile: {alnum_25th:.4f}\")\n",
                "    print(f\"   - Recommendation: Set min_ratio to {alnum_25th:.4f} (filters bottom 25%)\")\n",
                "    \n",
                "    # Generate optimized config based on 25th percentile\n",
                "    optimized_config = {\n",
                "        'language_id_score_filter': {\n",
                "            'min_score': float(f\"{lang_score_25th:.4f}\")\n",
                "        },\n",
                "        'text_length_filter': {\n",
                "            'min_len': int(text_len_25th),\n",
                "            'max_len': int(text_len_75th * 1.5)  # Allow some flexibility above 75th percentile\n",
                "        },\n",
                "        'alphanumeric_filter': {\n",
                "            'min_ratio': float(f\"{alnum_25th:.4f}\")\n",
                "        }\n",
                "    }\n",
                "    \n",
                "    print(\"\\n=== Optimized Configuration (Bottom 25% Filtered) ===\")\n",
                "    import json\n",
                "    print(json.dumps(optimized_config, indent=2))\n",
                "    \n",
                "    print(\"\\nðŸ“Š Strategy: Using 25th percentile ensures only top 75% quality samples are retained\")\n",
                "else:\n",
                "    print(\"Statistics file not found. Analysis may still be running.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Optimized Config File"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "optimized_config_yaml = \"\"\"\n",
                "project_name: 'analysis_demo_optimized'\n",
                "dataset_path: './outputs/analysis_demo/analyzed.jsonl' # Reuse samples with stats to save processing time\n",
                "export_path: './outputs/process_demo_optimized/processed.jsonl'\n",
                "\n",
                "np: 2\n",
                "\n",
                "process:\n",
                "  - language_id_score_filter:\n",
                "      lang: en\n",
                "      min_score: {lang_score}\n",
                "  \n",
                "  - text_length_filter:\n",
                "      min_len: {min_len}\n",
                "      max_len: {max_len}\n",
                "  \n",
                "  - alphanumeric_filter:\n",
                "      min_ratio: {alnum_ratio}\n",
                "\"\"\".format(\n",
                "    lang_score=optimized_config['language_id_score_filter']['min_score'],\n",
                "    min_len=optimized_config['text_length_filter']['min_len'],\n",
                "    max_len=optimized_config['text_length_filter']['max_len'],\n",
                "    alnum_ratio=optimized_config['alphanumeric_filter']['min_ratio']\n",
                ")\n",
                "\n",
                "# Save optimized config\n",
                "os.makedirs('./configs', exist_ok=True)\n",
                "with open('./configs/optimized_process.yaml', 'w') as f:\n",
                "    f.write(optimized_config_yaml)\n",
                "\n",
                "print(\"Optimized configuration saved to: ./configs/optimized_process.yaml\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Process with Optimized Parameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --keep_stats_in_res_ds true: Preserve statistical information in the result dataset\n",
                "#                               This allows skipping re-calculate in future iterations\n",
                "!dj-process --config ./configs/optimized_process.yaml \\\n",
                "    --keep_stats_in_res_ds true"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Checking processed dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('./outputs/process_demo_optimized/processed.jsonl', 'r') as f:\n",
                "    result = f.readlines()\n",
                "    print(f\"Processed dataset contains {len(result)} samples\")\n",
                "    for i, line in enumerate(result):\n",
                "        print(f\"{line}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Re-analyze Processed Data\n",
                "\n",
                "After processing, we re-analyze the processed dataset to:\n",
                "\n",
                "- Verify processing effectiveness: Check if low-quality samples were removed\n",
                "- Compare statistics: Before vs. after processing\n",
                "- Validate quality improvement: Ensure metrics moved in the desired direction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!dj-analyze --config ./configs/optimized_process.yaml \\\n",
                "    --dataset_path ./outputs/process_demo_optimized/processed.jsonl \\\n",
                "    --export_path ./outputs/processed_analyzed/analyzed.jsonl"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load overall statistics\n",
                "stats_file = './outputs/processed_analyzed/analysis/overall.csv'\n",
                "if os.path.exists(stats_file):\n",
                "    overall_stats = pd.read_csv(stats_file)\n",
                "    print(\"Overall Statistics:\")\n",
                "    print(overall_stats)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare Before and After Processing\n",
                "import matplotlib.gridspec as gridspec\n",
                "\n",
                "before_dir = './outputs/analysis_demo/analysis'\n",
                "after_dir = './outputs/processed_analyzed/analysis'\n",
                "\n",
                "# Get PNG files from both directories\n",
                "before_files = sorted([f for f in os.listdir(before_dir) if f.endswith('.png')]) if os.path.exists(before_dir) else []\n",
                "after_files = sorted([f for f in os.listdir(after_dir) if f.endswith('.png')]) if os.path.exists(after_dir) else []\n",
                "\n",
                "if before_files and after_files:\n",
                "    print(f\"Comparing {len(before_files)} visualizations before and after processing\\n\")\n",
                "    \n",
                "    # Compare matching files\n",
                "    for i, (before_file, after_file) in enumerate(zip(before_files[:3], after_files[:3])):\n",
                "        before_path = os.path.join(before_dir, before_file)\n",
                "        after_path = os.path.join(after_dir, after_file)\n",
                "        \n",
                "        before_img = Image.open(before_path)\n",
                "        after_img = Image.open(after_path)\n",
                "        \n",
                "        # Create side-by-side comparison\n",
                "        fig = plt.figure(figsize=(16, 6))\n",
                "        gs = gridspec.GridSpec(1, 2, figure=fig, wspace=0.3)\n",
                "        \n",
                "        # Before processing\n",
                "        ax1 = fig.add_subplot(gs[0, 0])\n",
                "        ax1.imshow(before_img)\n",
                "        ax1.set_title(f'Before Processing\\n{before_file}', fontsize=12, fontweight='bold')\n",
                "        ax1.axis('off')\n",
                "        \n",
                "        # After processing\n",
                "        ax2 = fig.add_subplot(gs[0, 1])\n",
                "        ax2.imshow(after_img)\n",
                "        ax2.set_title(f'After Processing\\n{after_file}', fontsize=12, fontweight='bold')\n",
                "        ax2.axis('off')\n",
                "        \n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "else:\n",
                "    print(\"Missing analysis directories or no visualization files found\")\n",
                "    if not before_files:\n",
                "        print(f\"  - Before: {before_dir} not found or empty\")\n",
                "    if not after_files:\n",
                "        print(f\"  - After: {after_dir} not found or empty\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Further Reading\n",
                "\n",
                "- [Analysis Tools](https://github.com/datajuicer/data-juicer/blob/main/tools/analyze_data.py)\n",
                "- [Operators Documentation](https://datajuicer.github.io/data-juicer/en/main/docs/Operators.html)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "data-juicer-nk",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
