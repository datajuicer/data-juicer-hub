{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 10: Advanced Dataset Configuration\n",
        "\n",
        "**Data-Juicer User Guide**\n",
        "\n",
        "- Git Commit: `v1.4.5`\n",
        "- Commit Date: 2026-01-16\n",
        "- Repository: https://github.com/datajuicer/data-juicer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. [Advanced Loading with DatasetCfg](#advanced-loading-with-datasetcfg)\n",
        "2. [Example 1: Sampling from Large Dataset](#example-1-sampling-from-large-dataset)\n",
        "3. [Example 2: Data Mixing with Weights](#example-2-data-mixing-with-weights)\n",
        "4. [Further Reading](#further-reading)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Loading with DatasetCfg\n",
        "\n",
        "For complex data loading scenarios, Data-Juicer provides `DatasetCfg` to handle:\n",
        "- Multiple data sources with different weights\n",
        "- Sampling from large datasets\n",
        "- Remote dataset loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See [DatasetCfg](https://datajuicer.github.io/data-juicer/en/main/docs/DatasetCfg.html) for complete documentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Data-Juicer (if not installed)\n",
        "# !uv pip install py-data-juicer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 1: Sampling from Large Dataset\n",
        "\n",
        "This example demonstrates how to sample a specific number of items from a large dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create large dataset\n",
        "large_data = [{\"text\": f\"Sample text number {i}\"} for i in range(100)]\n",
        "with open('./data/large.jsonl', 'w') as f:\n",
        "    for item in large_data:\n",
        "        f.write(json.dumps(item) + '\\n')\n",
        "\n",
        "print(f\"Created dataset with {len(large_data)} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading via Python API\n",
        "Use DatasetBuilder to verify that max_sample_num correctly limits the number of loaded samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jsonargparse import Namespace\n",
        "from data_juicer.core.data.dataset_builder import DatasetBuilder\n",
        "\n",
        "cfg = Namespace({\n",
        "    'dataset': {\n",
        "        'max_sample_num': 15,  # Load only 15 samples\n",
        "        'configs': [\n",
        "            {\n",
        "                'type': 'local',\n",
        "                'path': './data/large.jsonl'\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "})\n",
        "\n",
        "builder = DatasetBuilder(cfg)\n",
        "ds = builder.load_dataset()\n",
        "\n",
        "print(f\"Original samples: {len(large_data)}\")\n",
        "print(f\"Loaded samples: {len(ds)}\")\n",
        "print(f\"First sample: {ds[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Equivalent YAML Configuration for CLI Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile configs/sample_config.yaml\n",
        "project_name: 'sampling_demo'\n",
        "export_path: './outputs/sampled.jsonl'\n",
        "np: 1\n",
        "\n",
        "dataset:\n",
        "  max_sample_num: 15\n",
        "  configs:\n",
        "    - type: 'local'\n",
        "      path: './data/large.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dj-process --config ./configs/sample_config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Result Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./outputs/sampled.jsonl', 'r') as f:\n",
        "    sampled_count = sum(1 for line in f)\n",
        "print(f\"Original: {len(large_data)} samples\")\n",
        "print(f\"Processed & Sampled: {sampled_count} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Data Mixing with Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('./data/mix', exist_ok=True)\n",
        "\n",
        "en_data = [\n",
        "    {\"text\": \"Deep learning models require large amounts of training data.\"},\n",
        "    {\"text\": \"Attention mechanisms help models focus on relevant parts of input.\"},\n",
        "    {\"text\": \"Fine-tuning adapts pre-trained models to specific tasks.\"},\n",
        "    {\"text\": \"Batch normalization stabilizes neural network training.\"},\n",
        "    {\"text\": \"Transfer learning leverages knowledge from one domain to another.\"},\n",
        "    {\"text\": \"Loss functions measure the difference between predictions and targets.\"},\n",
        "    {\"text\": \"Backpropagation computes gradients for model optimization.\"},\n",
        "    {\"text\": \"Embeddings represent words or tokens as dense vectors.\"},\n",
        "    {\"text\": \"Overfitting can be mitigated with dropout or regularization.\"},\n",
        "    {\"text\": \"The transformer architecture enables parallel sequence processing.\"}\n",
        "]\n",
        "\n",
        "zh_data = [\n",
        "    {\"text\": \"今天天气晴朗，适合外出散步。\"},\n",
        "    {\"text\": \"多读书可以开阔视野，增长知识。\"},\n",
        "    {\"text\": \"保持规律作息对身体健康非常重要。\"},\n",
        "    {\"text\": \"与家人共度时光是幸福的源泉。\"},\n",
        "    {\"text\": \"学习新技能需要坚持和耐心。\"},\n",
        "    {\"text\": \"听音乐有助于缓解压力和焦虑。\"}\n",
        "]\n",
        "\n",
        "with open('./data/mix/en.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in en_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "with open('./data/mix/zh.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for item in zh_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(\"✅ Created bilingual datasets for clear mixing verification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading via Python API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jsonargparse import Namespace\n",
        "from data_juicer.core.data.dataset_builder import DatasetBuilder\n",
        "\n",
        "cfg = Namespace({\n",
        "    'dataset': {\n",
        "        'max_sample_num': 10,\n",
        "        'configs': [\n",
        "            {\n",
        "                'type': 'local',\n",
        "                'path': './data/mix/en.jsonl',\n",
        "                'weight': 0.7\n",
        "            },\n",
        "            {\n",
        "                'type': 'local',\n",
        "                'path': './data/mix/zh.jsonl',\n",
        "                'weight': 0.3\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "})\n",
        "\n",
        "builder = DatasetBuilder(cfg)\n",
        "ds = builder.load_dataset()\n",
        "\n",
        "print(f\"Loaded {len(ds)} samples\")\n",
        "for sample in ds:\n",
        "    print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Equivalent YAML Configuration for CLI Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile configs/mix_config.yaml\n",
        "project_name: 'mix'\n",
        "export_path: './outputs/mix/mixed.jsonl'\n",
        "np: 1\n",
        "\n",
        "dataset:\n",
        "  max_sample_num: 10\n",
        "  configs:\n",
        "    - type: 'local'\n",
        "      path: './data/mix/en.jsonl'\n",
        "      weight: 0.7\n",
        "    - type: 'local'\n",
        "      path: './data/mix/zh.jsonl'\n",
        "      weight: 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dj-process --config ./configs/mix_config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Result Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./outputs/mix/mixed.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        print(json.loads(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Used in conjunction with operators:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile configs/mix_process.yaml\n",
        "project_name: 'mix_process'\n",
        "export_path: './outputs/mix_processed/mixed.jsonl'\n",
        "np: 1\n",
        "dataset:\n",
        "  max_sample_num: 10\n",
        "  configs:\n",
        "    - type: 'local'\n",
        "      path: './data/mix/en.jsonl'\n",
        "      weight: 0.7\n",
        "    - type: 'local'\n",
        "      path: './data/mix/zh.jsonl'\n",
        "      weight: 0.3\n",
        "\n",
        "process:\n",
        "  - language_id_score_filter:\n",
        "      lang: 'en'\n",
        "      min_score: 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!dj-process --config ./configs/mix_process.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./outputs/mix_processed/mixed.jsonl', 'r') as f:\n",
        "    for line in f:\n",
        "        print(json.loads(line))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Further Reading\n",
        "\n",
        "- [DatasetCfg Documentation](https://datajuicer.github.io/data-juicer/en/main/docs/DatasetCfg.html)\n",
        "- [Format Conversion Tools](https://datajuicer.github.io/data-juicer/en/main/tools/fmt_conversion/README.html)\n",
        "- [Complete Configuration Reference](https://github.com/datajuicer/data-juicer/blob/main/data_juicer/config/config_all.yaml)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data-juicer-nk",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
